{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import click\n",
    "import pickle\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import torch, torch.nn as nn\n",
    "import random\n",
    "import segmentation_models_pytorch as sm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from torch.autograd import Variable\n",
    "from losses_pytorch.segmentation.twodim.entropy_based_losses import cross_entropy_with_logits_loss\n",
    "\n",
    "from precode.models import UnetSm\n",
    "from precode.scoring import jaccard_score\n",
    "from precode.labels.wheat_segmentation import WHEAT_LABELS\n",
    "from precode.net_utils import init_determenistic, batch_ids_generator\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import invert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/jupyter-fly_cv/Igor/Plants/13-45:24-09-21_model_plant_segmentation.bin'\n",
    "model_path_2 = '/home/jupyter-fly_cv/Igor/Plants/06-44:15-03-22_model_plant_segmentation.bin'\n",
    "model_path_3 = '/home/jupyter-fly_cv/Igor/Plants/03-10:17-03-22_model_plant_segmentation.bin'\n",
    "model_path_4 = '/home/jupyter-fly_cv/Igor/Plants/04-39:24-03-22_model_plant_segmentation.bin'\n",
    "model_path_5 = '/home/jupyter-fly_cv/Igor/Plants/03-23:25-03-22_model_plant_segmentation.bin'\n",
    "model_path_6 = '/home/jupyter-fly_cv/Igor/Plants/14-47:11-04-22_model_plant_segmentation.bin'\n",
    "model_path_7 = '/home/jupyter-fly_cv/Igor/Plants/15-40:09-04-22_model_plant_segmentation.bin'\n",
    "model_checker_path = '/home/jupyter-fly_cv/Igor/Plants/model_segmentation_checker.bin'\n",
    "test_path = '/home/jupyter-fly_cv/Igor/Plants/Segment_dataset/test'\n",
    "train_path = '/home/jupyter-fly_cv/Igor/Plants/Segment_dataset/train'\n",
    "val_path = '/home/jupyter-fly_cv/Igor/Plants/Segment_dataset/val'\n",
    "img_path = '/home/jupyter-fly_cv/Igor/Plants/data/Гаплоиды/'\n",
    "img_path_pl_2 = '/home/jupyter-fly_cv/Igor/Plants_2/Train_old'\n",
    "img_path_new = '/home/jupyter-fly_cv/Igor/Plants/data/Новый признак/'\n",
    "train_path_new = '/home/jupyter-fly_cv/Igor/Plants/New_json/train'\n",
    "test_path_new = '/home/jupyter-fly_cv/Igor/Plants/New_json/test'\n",
    "\n",
    "test_pl_2 = '/home/jupyter-fly_cv/Igor/Plants_2/Segment/test'\n",
    "train_pl_2 = '/home/jupyter-fly_cv/Igor/Plants_2/Segment/train'\n",
    "val_pl_2 = '/home/jupyter-fly_cv/Igor/Plants_2/Segment/val'\n",
    "\n",
    "st_checker_size = (870, 1500)\n",
    "st_img_shape =(4750, 3170)\n",
    "st_checker_size_new = (200, 350)\n",
    "st_img_new = (3350, 2950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_jpg_img(path):\n",
    "    img_names = []\n",
    "\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames: \n",
    "            name = os.path.join(filename)\n",
    "            if name.split('.')[-1] != 'JPG':\n",
    "                continue\n",
    "            img_names.append(dirname + '/' + name)\n",
    "            \n",
    "    return img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concantinate_mask(masks):\n",
    "    fin_mask = np.zeros((masks[0].shape[0],masks[0].shape[1]))\n",
    "    for mask in masks:\n",
    "        fin_mask =fin_mask + mask\n",
    "    #plt.imshow(fin_mask, cmap = 'gray')\n",
    "    fin_mask = np.clip(fin_mask,0,1)\n",
    "    return fin_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([np.array([0,1,2.5,366]),\n",
    "             np.array([0,0,1,0]),\n",
    "             np.array([0,1,0,0]),\n",
    "             np.array([0,1,1,0])])\n",
    "b = np.array([np.array([0,1,2,3]),\n",
    "             np.array([0,0,1,0]),\n",
    "             np.array([0,1,0,0]),\n",
    "             np.array([0,1,1,-1])])\n",
    "concantinate_mask([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TGI(img,b,r,porog):\n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "    \n",
    "    TGI = b *B + G + r*R\n",
    "    \n",
    "    mask = np.ones((img.shape[0],img.shape[1]))\n",
    "    mask *= TGI \n",
    "    \n",
    "    mask = cv2.GaussianBlur(mask, (11, 11), cv2.BORDER_DEFAULT)\n",
    "    mask = cv2.threshold(mask,porog,255,cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    mask = mask.astype(np.uint8)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    mask_cont = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    cv2.fillPoly(mask_cont,[max_contours(contours)],1)\n",
    "    mask = mask_cont * mask\n",
    "    \n",
    "    mask = np.where(mask > 0, 1, 0).astype(np.uint8)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TGI_all(img,b,r,porog):\n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "    \n",
    "    TGI = b *B + G + r*R\n",
    "    \n",
    "    mask = np.ones((img.shape[0],img.shape[1]))\n",
    "    mask *= TGI \n",
    "    \n",
    "    mask = cv2.GaussianBlur(mask, (11, 11), cv2.BORDER_DEFAULT)\n",
    "    mask = cv2.threshold(mask,porog,255,cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    mask = mask.astype(np.uint8)\n",
    "\n",
    "    mask = np.where(mask > 0, 1, 0).astype(np.uint8)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TGI(img,tgi):\n",
    "    mask_tgi = TGI(img,tgi[0],tgi[1],tgi[2])\n",
    "    checker = color_checker_stripe(img,model_checker_path)\n",
    "    mask_tgi = mask_tgi * checker\n",
    "    return mask_tgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TGI_all(img,tgi):\n",
    "    mask_tgi = TGI_all(img,tgi[0],tgi[1],tgi[2])\n",
    "    checker = color_checker_stripe(img,model_checker_path)\n",
    "    mask_tgi = mask_tgi* checker\n",
    "    return mask_tgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "infer_aug = A.Compose([ \n",
    "                        A.Resize ( height=512,\n",
    "                                   width=512,\n",
    "                                   interpolation=1,\n",
    "                                   always_apply=False,\n",
    "                                   p=1. ),\n",
    "                        A.Normalize ( mean=(0.485, 0.456, 0.406),\n",
    "                                      std=(0.229, 0.224, 0.225),\n",
    "                                      max_pixel_value=255.0,\n",
    "                                      always_apply=False,\n",
    "                                      p=1.0 )\n",
    "                      ])\n",
    "\n",
    "\n",
    "class UnetSm(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = sm.Unet(in_channels=in_channels, classes=out_channels, **kwargs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.unet(inputs)\n",
    "\n",
    "def inverse_infer_aug(height, width):\n",
    "    return A.Compose([\n",
    "                       A.Resize ( height=height,\n",
    "                                  width=width,\n",
    "                                  interpolation=cv2.INTER_NEAREST,\n",
    "                                  always_apply=False,\n",
    "                                  p=1. ) \n",
    "                    ])\n",
    "\n",
    "    \n",
    "def create_model(model_file):\n",
    "    model = UnetSm( out_channels=2,\n",
    "                    encoder_name='efficientnet-b0' )\n",
    " \n",
    "    with open(model_file, 'rb') as f:\n",
    "        state = pickle.load(f)\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def torch_float(data, device):\n",
    "    return Variable(torch.FloatTensor(data)).to(device)\n",
    "\n",
    "def augmented_load(img, aug):\n",
    "    auged = aug(image=img)\n",
    "    aug_img = auged['image']\n",
    "\n",
    "    aug_img = aug_img.transpose(2, 0, 1)\n",
    "\n",
    "    return np.array([aug_img])\n",
    "\n",
    "def infer(model, img):\n",
    "    \n",
    "    imgs_batch_ = augmented_load(img, infer_aug)\n",
    "    imgs_batch = torch_float(imgs_batch_, torch.device('cuda'))\n",
    "\n",
    "    logits_batch = model(imgs_batch)\n",
    "\n",
    "    pred_masks_batch = logits_batch.argmax(dim=1)\n",
    "    pred_mask = pred_masks_batch.cpu().data.numpy()#[0]\n",
    "      #  print(pred_masks_batch.cpu().data.numpy().shape)\n",
    "\n",
    "    original_size = img.shape[:2]\n",
    "\n",
    "    original_pred_mask = inverse_infer_aug(*original_size)(image=pred_mask)['image']\n",
    "    original_pred_mask = original_pred_mask.astype('uint8') * 255 \n",
    "\n",
    "    return original_pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accur(mask_1,mask_2):\n",
    "    mask_3 = mask_1 * mask_2\n",
    "    new_mask = np.where(mask_3 > 0, 1,0)\n",
    "    non_zero_mask = np.nonzero(new_mask)[0]\n",
    "    if len(non_zero_mask.shape) < 1 or non_zero_mask.shape[0] == 0:\n",
    "        return 0\n",
    "    mask_2_new = np.where(mask_2 > 0, 1,0)\n",
    "    non_zero_mask_2 = np.nonzero(mask_2_new)[0]\n",
    "    return (non_zero_mask.shape[0])/(non_zero_mask_2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_contours(contours):\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return np.array([[0,0],[0,1],[1,0]])\n",
    "\n",
    "    max_cnt = contours[0] \n",
    "    max_area_cnt = -1\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > max_area_cnt:\n",
    "            max_area_cnt = area\n",
    "            max_cnt = cnt\n",
    "            \n",
    "    return max_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_pref_png(name, pref):\n",
    "    names = name.split('/')\n",
    "    png_names = names[-1].split('.')\n",
    "    names[-1] = png_names[0] + '.' + 'png'\n",
    "    names[-1] = pref + names[-1]\n",
    "    new_name = ''\n",
    "    for n in names:\n",
    "        if n != names[-1]:\n",
    "            new_name =new_name + n + '/'\n",
    "        else:\n",
    "            new_name =new_name + n\n",
    "    return new_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#решает задачу о поиске максимума целевой функции func\n",
    "def Genetic(Q,F,P_mut,number_iter,func):\n",
    "    \n",
    "    X_init = list()\n",
    "    X = list()\n",
    "    best_f = -99999\n",
    "    best_x = 'nothing'\n",
    "    Sample_f = list()\n",
    "    \n",
    "    #начальная популяция\n",
    "    X_init.append( (-0.25,-0.76,0.017) )\n",
    "   # X_init.append(( -0.4137177782777779,-0.4884255085460936, 21.8252589694986) )\n",
    "    for i in range(3*Q - 1):\n",
    "        b = random.uniform(-1,1)\n",
    "        r = random.uniform(-1,1)\n",
    "        porog = random.uniform(-20,100)\n",
    "        X_init.append( (b,r,porog) )\n",
    "        \n",
    "    for x in X_init:\n",
    "        f = func(x[0],x[1],x[2])\n",
    "        #print(f)\n",
    "        if f > best_f:\n",
    "            best_f = f\n",
    "            best_x = x\n",
    "            #print(best_f)    \n",
    "        \n",
    "        Sample_f.append(f)\n",
    "        \n",
    "        #print(-1)\n",
    "    \n",
    "    for x in zip(X_init,range(3*Q)):    \n",
    "        X.append(x)\n",
    "    \n",
    "    for i in range(number_iter):\n",
    "        print(Sample_f)\n",
    "        \n",
    "        #размножение(создание пар)  \n",
    "        Anc = list()\n",
    "        for x in X:\n",
    "            p1 = random.choice(X)\n",
    "            \n",
    "            X_no_p1 = X.copy()\n",
    "            X_no_p1.remove(p1)\n",
    "            \n",
    "            p2 = random.choice(X_no_p1)\n",
    "            \n",
    "            Anc.append( (p1,p2) )\n",
    "        \n",
    "        F_pl = 0\n",
    "        #рождение и отбор\n",
    "        for par in Anc:\n",
    "            ch_val = [-1,-1,-1]\n",
    "            for j in range(3):\n",
    "                p = random.choice(list(par))\n",
    "                mut =  random.choices([0,1], weights = [1-P_mut,P_mut])[0]\n",
    "                mut_2 = random.uniform(-0.001,0.001)\n",
    "               \n",
    "                if i >= 50:\n",
    "                     F_pl =0.5 \n",
    "                \n",
    "                if i >= 70:\n",
    "                     F_pl =1 \n",
    "                   \n",
    "                ch_val[j] = p[0][j]*(1 + mut_2)\n",
    "                if mut == 1:\n",
    "                    X_no_par = X.copy()\n",
    "                    if set(par[0]).issubset(X_no_par):\n",
    "                        X_no_par.remove(par[0])\n",
    "                    if set(par[1]).issubset(X_no_par):\n",
    "                        X_no_par.remove(par[1])\n",
    "                    if len(X_no_par) == 0:\n",
    "                        an_1 = ((0,0,0),-1)\n",
    "                        an_2 = ((0,0,0),-1)\n",
    "                    else:\n",
    "                        an_1 = random.choice(X_no_par)\n",
    "                        if set(an_1).issubset(X_no_par):\n",
    "                            X_no_par.remove(an_1)\n",
    "                        if len(X_no_par) == 0:\n",
    "                            an_2 = an_1\n",
    "                        else:\n",
    "                            an_2 = random.choice(X_no_par)\n",
    "                   \n",
    "                    ch_val[j] += F*(1+F_pl)*(an_1[0][j] - an_2[0][j])\n",
    "                \n",
    "            f_ch = func(ch_val[0],ch_val[1],ch_val[2])\n",
    "            #print(f_ch)\n",
    "            \n",
    "            f_1 = Sample_f[par[0][1]]\n",
    "            f_2 = Sample_f[par[1][1]]\n",
    "            \n",
    "            index_bad_par = par[0][1]\n",
    "            if f_1 > f_2:\n",
    "                index_bad_par = par[1][1]\n",
    "        \n",
    "            if f_ch > Sample_f[index_bad_par]:\n",
    "                X[index_bad_par] = ((ch_val[0],ch_val[1],ch_val[2]),index_bad_par)\n",
    "                Sample_f[index_bad_par] = f_ch\n",
    "                \n",
    "                if f_ch > best_f:\n",
    "                    best_f = f_ch\n",
    "                    best_x = (ch_val[0],ch_val[1],ch_val[2])\n",
    "                    #print(best_f)\n",
    "                    \n",
    "            #print(i)\n",
    "        \n",
    "    return best_f,best_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_contours_accur(contours,mask,porog_accur,porog_a = 0, porog_b = 999999999):\n",
    "    area_ind = []\n",
    "    new_cnt = []\n",
    "    list_area = []\n",
    "    list_cnt = []\n",
    "    \n",
    "    i = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > porog_a and area < porog_b:\n",
    "            area_ind.append((area,i))\n",
    "            i += 1\n",
    "            list_cnt.append(cnt)\n",
    "    \n",
    "    if len(area_ind) == 0:\n",
    "        return 0\n",
    "    \n",
    "    area_ind = sorted(area_ind, key = lambda x: -x[0])\n",
    "    \n",
    "    for i in range(100):\n",
    "        if i >= len(list_cnt):\n",
    "            break\n",
    "        mask_cont = np.zeros((mask.shape[0],mask.shape[1])).astype(np.uint8)\n",
    "        cnt = list_cnt[area_ind[i][1]]\n",
    "        cv2.fillPoly(mask_cont,[cnt],1)\n",
    "#         plt.imshow(mask_cont,cmap = 'gray')\n",
    "#         print(accur(mask_cont,mask))\n",
    "#         break\n",
    "        if accur(mask_cont,mask) > porog_accur :\n",
    "            new_cnt.append(cnt)\n",
    "            print('hey')\n",
    "    \n",
    "    return np.array(new_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle(mask):\n",
    "    new_mask = np.where(mask > 0, 1,0)\n",
    "    non_zero_mask = np.nonzero(new_mask)\n",
    "    h = non_zero_mask[0].max() - non_zero_mask[0].min()\n",
    "    w = non_zero_mask[1].max() - non_zero_mask[1].min()\n",
    "    x = set(non_zero_mask[1])\n",
    "    y = set(non_zero_mask[0])\n",
    "    x = sum(x)/len(x)\n",
    "    y = sum(y)/len(y)\n",
    "    return w,h,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_checker_stripe(img,model_checker_path):\n",
    "    img_checker = infer(create_model(model_checker_path),img)\n",
    "    img_checker = cv2.GaussianBlur(img_checker, (21, 21), 0)\n",
    "   # img_checker = np.round(img_checker/255)\n",
    "   \n",
    "    img_checker = cv2.threshold(img_checker,15,255,cv2.THRESH_BINARY)[1] \n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(img_checker,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    img_checker = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    cv2.fillPoly(img_checker,[max_contours(contours)],1)\n",
    "\n",
    "    checker_stripe = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    w,h,x,y = rectangle(img_checker)\n",
    "    w_2 = int(w/2) +1\n",
    "    h_2 = int(h/2) + 1\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    \n",
    "    im_h = img.shape[0]\n",
    "    \n",
    "    points = np.array([(int(x + w_2),int(im_h)),(int(0),int(im_h)),(int(0),int(y - h_2)),(int(x + w_2),int(y - h_2))])\n",
    "    cv2.fillPoly(checker_stripe,[points],1)   \n",
    "\n",
    "    return 1 - checker_stripe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_checker_rect(img,mask):\n",
    "    img_checker = infer(create_model(model_checker_path),img)\n",
    "    img_checker = cv2.GaussianBlur(img_checker, (21, 21), 0)\n",
    "#    img_checker = np.round(img_checker/255)\n",
    "   \n",
    "    img_checker = cv2.threshold(img_checker,19,255,cv2.THRESH_BINARY)[1] \n",
    "    \n",
    "    pot_mask = pot_segment(img,mask)\n",
    "    img_checker *= 1 - pot_mask\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(img_checker,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    img_checker = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    cv2.fillPoly(img_checker,[max_contours(contours)],1)\n",
    "\n",
    "    checker_stripe = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    w,h,x,y = rectangle(img_checker)\n",
    "    w_2 = int(w/2) +1\n",
    "    h_2 = int(h/2) + 1\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    \n",
    "    \n",
    "    points = np.array([(int(x + w_2),int(y + h_2)),(int(x - w_2),int(y + h_2)),(int(x - w_2),int(y - h_2)),(int(x + w_2),int(y - h_2))])\n",
    "    cv2.fillPoly(checker_stripe,[points],1)   \n",
    "    \n",
    "    return w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant_rectangle(img,mask,extra_w = 0,extra_h = 0):\n",
    "    \n",
    "    w,h,x,y = rectangle(mask)\n",
    "    #y = img.shape[0] -y\n",
    "    stripe = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    w *=(1 + extra_w) \n",
    "    h *=(1 + extra_h) \n",
    "    w_2 = int(w/2)\n",
    "    h_2 = int(h/2)\n",
    "    x = int(x)\n",
    "    \n",
    "    points = np.array([(int(x + w_2),int(y + h_2)),(int(x - w_2),int(y + h_2)),(int(x - w_2),int(y - h_2)),(int(x + w_2),int(y - h_2))])\n",
    "    cv2.fillPoly(stripe,[points],1)   \n",
    "        \n",
    "    stripe = np.where(stripe > 0, 1,0)\n",
    "    stripe = stripe.astype(np.uint8)\n",
    "    \n",
    "    return stripe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot_segment(img,mask):\n",
    "    img_checker = color_checker_stripe(img,model_checker_path).astype(np.uint8)\n",
    "    stripe = plant_stripe(img,mask,extra_w = 0.0)\n",
    "    bl_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    new_img = stripe * bl_img*img_checker\n",
    "    plant_mask = np.where(mask > 0, 0,1).astype(np.uint8)\n",
    "    new_img *= plant_mask\n",
    "    new_img = cv2.threshold(new_img,19,255,cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(new_img,cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    pot = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    cv2.fillPoly(pot,[max_contours(contours)],1)\n",
    "    \n",
    "    plant_mask = np.where(mask > 0, 2,1).astype(np.uint8)  \n",
    "    w,h,x,y = rectangle(pot)\n",
    "    pot = np.zeros((img.shape[0],img.shape[1])).astype(np.uint8)\n",
    "    w = w #* 1.1\n",
    "    w_2 = int(w/2) +1\n",
    "    h_2 = int(h/2) + 1\n",
    "    points = np.array([(int(x + w_2),int(y + h_2)),(int(x - w_2),int(y + h_2)),(int(x - w_2),int(y - h_2)),(int(x + w_2),int(y - h_2))])\n",
    "    cv2.fillPoly(pot,[points],1)\n",
    "    \n",
    "    pot = pot*plant_mask\n",
    "    pot = np.where(pot == 1, 1,0).astype(np.uint8)\n",
    "    \n",
    "    return pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant_stripe(img,mask,extra_w = 0):\n",
    "    \n",
    "    w,h,x,y = rectangle(mask)\n",
    "    stripe = mask.copy()\n",
    "    w *=(1 + extra_w) \n",
    "    w_2 = int(w/2)\n",
    "    x = int(x) - 1\n",
    "    \n",
    "    for i in range(int(w) + 1+100):\n",
    "        if x-w_2+i >= 0 and  x-w_2+i < img.shape[1]:\n",
    "            stripe[:,x-w_2+i] = np.zeros(stripe.shape[0]).astype(np.uint8) + 255\n",
    "        \n",
    "    stripe = np.where(stripe > 0, 1,0)\n",
    "    stripe = stripe.astype(np.uint8)\n",
    "    \n",
    "    return stripe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_mask(seg_model,model_checker_path, img):\n",
    "    mask = infer(seg_model,img)\n",
    "    checker = color_checker_stripe(img,model_checker_path)\n",
    "    mask = mask * checker\n",
    "    mask = cv2.GaussianBlur(mask, (11, 11), cv2.BORDER_DEFAULT)\n",
    "    mask = cv2.threshold(mask,15,255,cv2.THRESH_BINARY)[1]\n",
    "     \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_img(img,min_img):\n",
    "    new_img = img.copy()\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        new_img[:,:,0] = new_img[:,:,0] * min_img\n",
    "        new_img[:,:,1] = new_img[:,:,1] * min_img\n",
    "        new_img[:,:,2] = new_img[:,:,2] * min_img\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        new_img = new_img * min_img\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_segment(img,seg_model, tgi,tgi_all = (-0.7527070259382189, 0.015372226467469639, 18.627924485740596) ):\n",
    "    \n",
    "    img_checker = color_checker_stripe(img,model_checker_path).astype(np.uint8)\n",
    "    mask_unet = pred_mask(seg_model, model_checker_path, img)\n",
    "    mask_tgi = get_TGI(img,tgi)*img_checker\n",
    "    mask_tgi_all = get_TGI_all(img,tgi_all)\n",
    "    mask = concantinate_mask([mask_tgi,mask_unet])\n",
    "    \n",
    "    bl_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    pot_mask = pot_segment(img,mask)\n",
    "    plant_mask = plant_rectangle(img,mask)\n",
    "    \n",
    "    mask_tgi_all *= (1-pot_mask)\n",
    "    mask_tgi_all *= plant_mask\n",
    "    \n",
    "    return concantinate_mask([mask_tgi,mask_tgi_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_load2(img, aug):\n",
    "    auged = aug(image=img)\n",
    "    aug_img = auged['image']\n",
    "\n",
    "    aug_img = aug_img.transpose(2, 0, 1)\n",
    "\n",
    "    return np.array([aug_img])\n",
    "\n",
    "def infer(model, img):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        imgs_batch_ = augmented_load2(img, infer_aug)\n",
    "        imgs_batch = torch_float(imgs_batch_, config['DEVICE'])\n",
    "\n",
    "        logits_batch = model(imgs_batch)\n",
    "\n",
    "        pred_masks_batch = logits_batch.argmax(dim=1)\n",
    "        pred_mask = pred_masks_batch.cpu().data.numpy()[0]\n",
    "\n",
    "        original_size = img.shape[:2]\n",
    "\n",
    "        original_pred_mask = inverse_infer_aug(*original_size)(image=pred_mask)['image']\n",
    "        original_pred_mask = original_pred_mask.astype('uint8') * 255 \n",
    "\n",
    "    return original_pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = {}\n",
    "    datapath = Path(config['DATAPATH'])\n",
    "    \n",
    "    for name, folder_name in ([ ('train', 'train'),\n",
    "                                ('val', 'val') ]):\n",
    "        imgpathes = list()\n",
    "        maskpathes = list()\n",
    "        \n",
    "        for imgpath in (datapath / folder_name).glob('*.jpg'):\n",
    "            \n",
    "            #suff = str(imgpath).split('.')[-1]\n",
    "            #if suff == 'jpg':\n",
    "            imgpathes.append(imgpath)\n",
    "            mask_name = imgpath.name.replace('.png','.png')\n",
    "            maskpathes.append(imgpath.with_name(mask_name))\n",
    "\n",
    "        data[name] = (np.array(imgpathes), np.array(maskpathes))\n",
    "    \n",
    "    print(data)\n",
    "    return data\n",
    "\n",
    "def torch_long(data, device):\n",
    "    return Variable(torch.LongTensor(data)).to(device)\n",
    "\n",
    "def torch_float(data, device):\n",
    "    return Variable(torch.FloatTensor(data)).to(device) #new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_load(imgpathes, maskpathes, aug):\n",
    "    images = list()\n",
    "    masks = list()\n",
    "\n",
    "    for imgpath, maskpath in zip(imgpathes, maskpathes):\n",
    "        if os.path.exists(imgpath) and os.path.exists(maskpath):\n",
    "            img = imread(imgpath)\n",
    "            ch_stripe = color_checker_stripe(img,model_checker_path)\n",
    "            img =  minus_img(img,ch_stripe)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            mask = imread(maskpath,cv2.IMREAD_GRAYSCALE)\n",
    "            mask = minus_img(mask, ch_stripe)\n",
    "            mask = mask.clip(max=1)\n",
    "            \n",
    "            \n",
    "            if len(mask.shape) <= 2:\n",
    "                auged = aug(image=img, mask=mask)\n",
    "                aug_img = auged['image']\n",
    "                aug_mask = auged['mask']\n",
    "        \n",
    "                aug_img = aug_img.transpose(2, 0, 1)\n",
    "\n",
    "                images.append(aug_img)\n",
    "                masks.append(aug_mask)\n",
    "            \n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_aug = A.Compose([ \n",
    "                        A.Resize ( height=512,\n",
    "                                   width=512,\n",
    "                                   interpolation=1,\n",
    "                                   always_apply=False,\n",
    "                                   p=1. ),\n",
    "                        A.Normalize ( mean=(0.485, 0.456, 0.406),\n",
    "                                      std=(0.229, 0.224, 0.225),\n",
    "                                      max_pixel_value=255.0,\n",
    "                                      always_apply=False,\n",
    "                                      p=1.0 )\n",
    "                      ])\n",
    "\n",
    "def inverse_infer_aug(height, width):\n",
    "    return A.Compose([\n",
    "                       A.Resize ( height=height,\n",
    "                                  width=width,\n",
    "                                  interpolation=cv2.INTER_NEAREST,\n",
    "                                  always_apply=False,\n",
    "                                  p=1. ) \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    imgpathes = []\n",
    "    maskpathes= []\n",
    "    for imgpath in os.listdir(path):\n",
    "            if imgpath.split('.')[-1] == 'jpg':\n",
    "                imgpathes.append(path + '/' + imgpath)\n",
    "                mask_name = imgpath.replace('.jpg','_mask.png')\n",
    "                maskpathes.append(path + '/' + mask_name)              \n",
    "    return imgpathes, maskpathes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_segment_aug(tgi,imgpathes,seg_model, aug):\n",
    "    masks = list()\n",
    "\n",
    "    for imgpath in imgpathes:\n",
    "            \n",
    "        img = imread(imgpath)\n",
    "        ch_stripe = color_checker_stripe(img,model_checker_path)\n",
    "        img =  minus_img(img,ch_stripe)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = final_segment(img,seg_model, tgi)\n",
    "        mask = minus_img(mask, ch_stripe)\n",
    "        mask = mask.clip(max=1)\n",
    "            \n",
    "            \n",
    "        auged = aug(image=img, mask=mask)\n",
    "#            aug_img = auged['image']\n",
    "        aug_mask = auged['mask']\n",
    "        \n",
    "#            aug_img = aug_img.transpose(2, 0, 1)\n",
    "\n",
    "        masks.append(aug_mask)\n",
    "\n",
    "            \n",
    "    return np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TGI_aug(tgi,imgpathes, aug):\n",
    "    masks = list()\n",
    "\n",
    "    for imgpath in imgpathes:\n",
    "            \n",
    "            img = imread(imgpath)\n",
    "            ch_stripe = color_checker_stripe(img,model_checker_path)\n",
    "            img =  minus_img(img,ch_stripe)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "#            b,r, porog = tgi\n",
    "        \n",
    "            mask = get_TGI(img,tgi)\n",
    "            mask = minus_img(mask, ch_stripe)\n",
    "            mask = mask.clip(max=1)\n",
    "            \n",
    "            auged = aug(image=img, mask=mask)\n",
    "#            aug_img = auged['image']\n",
    "            aug_mask = auged['mask']\n",
    "        \n",
    "#            aug_img = aug_img.transpose(2, 0, 1)\n",
    "\n",
    "            masks.append(aug_mask)\n",
    "\n",
    "            \n",
    "    return np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_test_loop(model, imgpathes, maskpathes):\n",
    "    model.eval()\n",
    "    size = len(maskpathes)\n",
    "\n",
    "    masks = list()\n",
    "    pred_masks = list()\n",
    "    batch_losses = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "            #imgpathes_batch = imgpathes[batch_ids]\n",
    "            #maskpathes_batch = maskpathes[batch_ids]\n",
    "\n",
    "            imgs_batch, masks_batch = augmented_load(imgpathes, maskpathes, infer_aug)\n",
    "\n",
    "            imgs_batch = torch_float(imgs_batch, config['DEVICE']).cpu()      \n",
    "            masks_batch = torch_long(masks_batch, config['DEVICE']).cpu()\n",
    "\n",
    "            logits_batch = model(imgs_batch.cuda()).cpu()\n",
    "            loss = cross_entropy_with_logits_loss(masks_batch, logits_batch)\n",
    "\n",
    "            pred_masks_batch = logits_batch.argmax(dim=1)\n",
    "            pred_masks_batch = pred_masks_batch.cpu().data.numpy()\n",
    "\n",
    "            masks.append(masks_batch)\n",
    "            #plt.imshow(masks_batch, cmap = 'gray')\n",
    "            pred_masks.append(pred_masks_batch)\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "           # del imgpathes_batch, maskpathes_batch, imgs_batch\n",
    "#     # torch.cuda.empty_cache()\n",
    "\n",
    "    masks = np.concatenate(masks)\n",
    "    pred_masks = np.concatenate(pred_masks)\n",
    "    \n",
    "    masks = masks.clip(max=1)\n",
    "    pred_masks = pred_masks.clip(max=1)\n",
    "    \n",
    "   #print(type(masks))\n",
    "\n",
    "    jaccard_score_none = jaccard_score(masks, pred_masks, average='none')\n",
    "\n",
    "    score = jaccard_score_none[1]\n",
    "\n",
    "    return score, np.mean(batch_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_final_segment(model,tgi,imgpathes, maskpathes):\n",
    "   \n",
    "    size = len(maskpathes)\n",
    "\n",
    "    masks = list()\n",
    "    pred_masks = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            \n",
    "            imgs_batch, masks_batch = augmented_load(imgpathes, maskpathes, infer_aug)\n",
    "\n",
    "            imgs_batch = torch_float(imgs_batch, config['DEVICE']).cpu()      \n",
    "            masks_batch = torch_long(masks_batch, config['DEVICE']).cpu()\n",
    "                \n",
    "            pred_masks_batch = final_segment_aug(tgi,imgpathes, model,infer_aug)\n",
    "            pred_masks_batch = torch_long(pred_masks_batch, config['DEVICE']).cpu()\n",
    "            #pred_masks_batch_tgi = pred_masks_batch_tgi.argmax(dim=1)\n",
    "            #pred_masks_batch = pred_masks_batch.cpu().data.numpy()\n",
    "            \n",
    "            masks.append(masks_batch)\n",
    "            pred_masks.append(pred_masks_batch)\n",
    "\n",
    "    masks = np.concatenate(masks)\n",
    "    pred_masks = np.concatenate(pred_masks)\n",
    "    \n",
    "    masks = masks.clip(max=1)\n",
    "    pred_masks = pred_masks.clip(max=1)\n",
    "\n",
    "    jaccard_score_none = jaccard_score(masks, pred_masks, average='none')\n",
    "\n",
    "    score = jaccard_score_none[1]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_TGI(tgi,imgpathes, maskpathes):\n",
    " \n",
    "    size = len(maskpathes)\n",
    "\n",
    "    masks = list()\n",
    "    pred_masks = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            \n",
    "            imgs_batch, masks_batch = augmented_load(imgpathes, maskpathes, infer_aug)\n",
    "\n",
    "            imgs_batch = torch_float(imgs_batch, config['DEVICE']).cpu()      \n",
    "            masks_batch = torch_long(masks_batch, config['DEVICE']).cpu()\n",
    "\n",
    "            pred_masks_batch = TGI_aug(tgi,imgpathes,infer_aug)\n",
    "            pred_masks_batch = torch_long(pred_masks_batch, config['DEVICE']).cpu()\n",
    "                    \n",
    "            masks.append(masks_batch)\n",
    "            pred_masks.append(pred_masks_batch)\n",
    "\n",
    "    masks = np.concatenate(masks)\n",
    "    pred_masks = np.concatenate(pred_masks)\n",
    "    \n",
    "    masks = masks.clip(max=1)\n",
    "    pred_masks = pred_masks.clip(max=1)\n",
    "    \n",
    "    jaccard_score_none = jaccard_score(masks, pred_masks, average='none')\n",
    "\n",
    "    score = jaccard_score_none[1]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_multi_model_TGI(models,tgi,imgpathes, maskpathes):\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "   \n",
    "    size = len(maskpathes)\n",
    "    pred_masks = np.array(list()).astype(np.uint8)\n",
    "    pred_masks_tgi =  np.array(list()).astype(np.uint8)\n",
    "    masks = list()\n",
    "    model_mask = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            \n",
    "            imgs_batch, masks_batch = augmented_load(imgpathes, maskpathes, infer_aug)\n",
    "\n",
    "            imgs_batch = torch_float(imgs_batch, config['DEVICE']).cpu()      \n",
    "            masks_batch = torch_long(masks_batch, config['DEVICE']).cpu()\n",
    "\n",
    "            for model in models:\n",
    "                logits_batch = model(imgs_batch.cuda()).cpu()\n",
    "\n",
    "                pred_masks_batch = logits_batch.argmax(dim=1)\n",
    "                pred_masks_batch = pred_masks_batch.cpu().data.numpy()\n",
    "                model_mask.append(pred_masks_batch)\n",
    "                \n",
    "            #model_mask.append(pred_masks_batch)\n",
    "                \n",
    "            pred_masks_batch_tgi = TGI_aug(tgi,imgpathes, infer_aug)\n",
    "            pred_masks_batch_tgi = torch_long(pred_masks_batch_tgi, config['DEVICE']).cpu()\n",
    "           # pred_masks_batch_tgi = pred_masks_batch_tgi.argmax(dim=1)\n",
    "            #pred_masks_batch_tgi = pred_masks_batch_tgi.cpu().data.numpy()\n",
    "            #model_mask.append(pred_masks_batch_tgi)\n",
    "            \n",
    "            masks.append(masks_batch)\n",
    "\n",
    "    masks = np.concatenate(masks)\n",
    "    \n",
    "    pred_masks = np.concatenate(model_mask[0])\n",
    "    for m_mask in model_mask:\n",
    "        pred_masks = concantinate_mask([np.concatenate(m_mask),pred_masks])\n",
    "    \n",
    "    pred_masks_tgi = np.concatenate([pred_masks_batch_tgi])\n",
    "    pred_masks_tgi = np.resize(pred_masks_tgi,(pred_masks.shape[0],pred_masks.shape[1]))\n",
    "    pred_masks = concantinate_mask([pred_masks,pred_masks_tgi])\n",
    "    \n",
    "    pred_masks = np.resize(pred_masks,(masks.shape[0],masks.shape[1],masks.shape[2]))\n",
    "    \n",
    "    masks = masks.clip(max=1)\n",
    "    pred_masks = pred_masks.clip(max=1)\n",
    "    \n",
    "    jaccard_score_none = jaccard_score(masks, pred_masks, average='none')\n",
    "\n",
    "    score = jaccard_score_none[1]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_multi_model(models,imgpathes, maskpathes):\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "   \n",
    "    size = len(maskpathes)\n",
    "    pred_masks = np.array(list()).astype(np.uint8)\n",
    "    masks = list()\n",
    "    model_mask = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            \n",
    "            imgs_batch, masks_batch = augmented_load(imgpathes, maskpathes, infer_aug)\n",
    "\n",
    "            imgs_batch = torch_float(imgs_batch, config['DEVICE']).cpu()      \n",
    "            masks_batch = torch_long(masks_batch, config['DEVICE']).cpu()\n",
    "\n",
    "            for model in models:\n",
    "                logits_batch = model(imgs_batch.cuda()).cpu()\n",
    "\n",
    "                pred_masks_batch = logits_batch.argmax(dim=1)\n",
    "                pred_masks_batch = pred_masks_batch.cpu().data.numpy()\n",
    "                model_mask.append(pred_masks_batch)\n",
    "            \n",
    "            masks.append(masks_batch)\n",
    "\n",
    "    masks = np.concatenate(masks)\n",
    "    \n",
    "    pred_masks = np.concatenate(model_mask[0])\n",
    "\n",
    "    for m_mask in model_mask:\n",
    "        pred_masks = concantinate_mask([np.concatenate(m_mask),pred_masks])\n",
    "    \n",
    "    pred_masks = np.resize(pred_masks,(masks.shape[0],masks.shape[1],masks.shape[2]))\n",
    "  \n",
    "    masks = masks.clip(max=1)\n",
    "    pred_masks = pred_masks.clip(max=1)\n",
    "    \n",
    "    jaccard_score_none = jaccard_score(masks, pred_masks, average='none')\n",
    "\n",
    "    score = jaccard_score_none[1]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21807/3975723345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_test_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pl_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_test_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pl_2_dip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#print(inner_test_loop(model3, img_names, mask_names))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21807/402023498.py\u001b[0m in \u001b[0;36minner_test_loop\u001b[0;34m(model, imgpathes, maskpathes)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmasks_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DEVICE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mlogits_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_with_logits_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21807/2561541910.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minverse_infer_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;34m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mcheck_input_shape\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moutput_stride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutput_stride\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutput_stride\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "model1 = create_model(model_path)\n",
    "model2 = create_model(model_path_2)\n",
    "model4 = create_model(model_path_4)\n",
    "model5 = create_model(model_path_5)\n",
    "\n",
    "model_pl_2 = create_model(model_path_7)\n",
    "model_pl_2_dip = create_model(model_path_6)\n",
    "\n",
    "img_names,mask_names = load_test_data(train_pl_2) \n",
    "img_names\n",
    "\n",
    "print(inner_test_loop(model_pl_2, img_names, mask_names))\n",
    "print(inner_test_loop(model_pl_2_dip, img_names, mask_names))\n",
    "#print(inner_test_loop(model3, img_names, mask_names))\n",
    "\n",
    "#print(jaccard_multi_model([model2],img_names,mask_names))\n",
    "#print(jaccard_multi_model([model1,model2,model3],img_names,mask_names))\n",
    "#print(jaccard_multi_model([model1,model2],img_names,mask_names))\n",
    "#print(jaccard_multi_model([model1,model3],img_names,mask_names))\n",
    "#print(jaccard_multi_model([model2,model3],img_names,mask_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = create_model(model_path_2)\n",
    "img_names,mask_names = load_test_data(val_path)\n",
    "print(inner_test_loop(model2, img_names, mask_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masks = np.array(list()).astype(np.uint8)\n",
    "pred_masks.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names,mask_names = load_test_data(test_path_new) \n",
    "print(jaccard_final_segment(model2,(-0.4525162720429479, -0.4636879441900241, 20.541210574133643) ,img_names, mask_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для проверки генетического алгоритма\n",
    "def f1(a,b,c):\n",
    "    return -abs(a*a*a+2*b*b+3*c - 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_func_tgi(b,r,porog):\n",
    "    img_names,mask_names = load_test_data(val_path)\n",
    "    jaccard = jaccard_TGI((b,r,porog),img_names, mask_names)\n",
    "    return  jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_func_tgi_train_pl2(b,r,porog):\n",
    "    img_names,mask_names = load_test_data(img_path_pl_2)\n",
    "    jaccard = jaccard_TGI((b,r,porog),img_names, mask_names)\n",
    "    return  jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_func_tgi_train(b,r,porog):\n",
    "    img_names,mask_names = load_test_data(train_path)\n",
    "    jaccard = jaccard_TGI((b,r,porog),img_names, mask_names)\n",
    "    return  jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_func_tgi_train_new(b,r,porog):\n",
    "    img_names,mask_names = load_test_data(train_path_new)\n",
    "    jaccard = jaccard_TGI((b,r,porog),img_names, mask_names)\n",
    "    return  jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_func_tgi_train(  -0.3888966243829097,-0.5302251579522758, 19.5706352334385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_func_tgi_train(b,r,porog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genetic(5,0.5,0.5,100,jaccard_func_tgi_train_pl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names,mask_names = load_test_data(img_path_pl_2)\n",
    "mask_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_func_tgi( *(-0.428685910442829, -0.49736106371992633, 17.1750795654293))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genetic(5,0.5,0.5,10000,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genetic(1,1,0.5,10,jaccard_func_tgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par = (0,0)\n",
    "best_jaccard = -1\n",
    "for F in range(3,6,1):\n",
    "    for P_mut in range(3,11):\n",
    "        f = F/10\n",
    "        p_mut = P_mut/10\n",
    "        print()\n",
    "        print(f)\n",
    "        print(p_mut)\n",
    "        jaccard,gti = Genetic(2,f,p_mut,10,jaccard_func_tgi)\n",
    "        print('jacc: ' + str(jaccard))\n",
    "        if jaccard > best_jaccard:\n",
    "            best_jaccard = jaccard\n",
    "            best_par = (f,p_mut)\n",
    "            print('new best:')\n",
    "            print(gti)\n",
    "            print(jaccard)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genetic(3,0.5,0.5,100,jaccard_func_tgi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = create_model(model_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names,mask_names = load_test_data(test_path_new)\n",
    "jaccard_TGI( (-0.5508976263096602, -0.12285704107229999, 21.31430587433073)  ,img_names, mask_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names,mask_names = load_test_data(train_path)\n",
    "jaccard_final_segment(model2,( -0.4636879441900241,-0.4525162720429479, 20.541210574133643)  ,img_names, mask_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('/home/jupyter-fly_cv/Igor/Plants_2/train_Demo/DJI_0268_mask.png',cv2.IMREAD_GRAYSCALE)[:,:,0]\n",
    "plt.imshow(img,cmap = 'gray')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names,mask_names = load_test_data(test_path_new) \n",
    "jaccard_multi_model_TGI([model2],(-0.5508976263096602, -0.12285704107229999, 21.31430587433073),img_names, mask_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgi = (-0.428685910442829, -0.49736106371992633, 17.1750795654293)\n",
    "# #jaccard_train = 0.773232962494171\n",
    "# #jaccard_val = 0.7796997163218709\n",
    "# #jaccard_test = 0.8213170879065552\n",
    "# #jaccard_multi = 0.7471617991160413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgi = (-0.4137177782777779, -0.4884255085460936, 21.8252589694986)\n",
    "# #jaccard_train = 0.7766485843118405\n",
    "# #jaccard_val = 0.0.7803111780311178\n",
    "# #jaccard_test = 0.8213170879065552\n",
    "# #jaccard_multi = 0.7471617991160413"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgi =(-0.4525162720429479, -0.4636879441900241, 20.541210574133643) \n",
    "tgi =(-0.5508976263096602,-0.12285704107229999 , 21.31430587433073)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = np.array([[0,0,1,0,1],\n",
    "                [1,0,1,0,1]])\n",
    "m_2 = np.array([[0,0,1,0,0],\n",
    "                [1,0,1,5,1]])\n",
    "accur(m_1,m_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_filename(name):\n",
    "    names = name.split('/')\n",
    "    direct = ''\n",
    "    for n in names:\n",
    "        if n == names[-1]:\n",
    "            continue\n",
    "        direct = direct + n + '/' \n",
    "    return direct   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_4_folder(path):\n",
    "    names = path.split('/')\n",
    "    for name in names:\n",
    "        if name == '4':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-fly_cv/Igor/Plants/data/Новый признак/2022_03_11 Wheat/L-25/IMG_8319.JPG\n",
      "(4480, 6720)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tgi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21807/4125447430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmask_unet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checker_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     mask_tgi = get_TGI(img_res,tgi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmask_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     mask = concantinate_mask([mask_tgi,mask_unet])*255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     mask = cv2.GaussianBlur(mask, (21, 21), 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tgi' is not defined"
     ]
    }
   ],
   "source": [
    "seg_model = create_model(model_path)\n",
    "img_names = all_jpg_img(img_path_new)\n",
    "checker_model = create_model(model_checker_path)\n",
    "os.chdir('/home/jupyter-fly_cv/Igor/Plants')\n",
    "\n",
    "for name in img_names:\n",
    "\n",
    "    print(name)\n",
    "    img = cv2.imread(name)\n",
    "    img_res = cv2.resize(img,(int(st_img_new[1]), int(st_img_new[0])), interpolation = cv2.INTER_AREA)\n",
    "    print(color_checker_stripe(img,model_checker_path).astype(np.uint8).shape)\n",
    "    bl_img = cv2.cvtColor(img_res,cv2.COLOR_BGR2GRAY)\n",
    "    mask_unet = pred_mask(seg_model, model_checker_path, img_res)\n",
    "\n",
    "    mask_f = final_segment(img_res,seg_model, tgi)*255\n",
    "\n",
    "    w,h = color_checker_rect(img_res,mask_f);\n",
    "    print(w,h)\n",
    "    w = st_checker_size_new[0]/w\n",
    "    h = st_checker_size_new[1]/h\n",
    "    \n",
    "    mask = cv2.resize(mask_f,(int(mask_f.shape[1]*w), int(mask_f.shape[0]*h)), interpolation = cv2.INTER_AREA)\n",
    "   \n",
    "    cv2.imwrite('mask_1.png',mask_unet)\n",
    "    break\n",
    "    os.chdir(direct_filename(name))\n",
    "    cv2.imwrite(filename_pref_png(name.split('/')[-1].split('.')[0], 'mask_'), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = all_jpg_img(img_path_pl_2)\n",
    "os.chdir(img_path_pl_2)\n",
    "\n",
    "for name in all_jpg_img(img_path_pl_2):\n",
    "    print(name)\n",
    "    img = cv2.imread(name)\n",
    "    mask_tgi = get_TGI(img,( -0.8059495495534817,-0.1761912501892932, 15.560133069974423))\n",
    "    cv2.imwrite(filename_pref_png(name.split('/')[-1].split('.')[0], 'mask_tgi_'), mask_tgi*255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
