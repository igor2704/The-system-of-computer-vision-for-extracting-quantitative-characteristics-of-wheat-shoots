{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /opt/tljh/user/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import math as mth\n",
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import click\n",
    "import pickle\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import torch, torch.nn as nn\n",
    "import segmentation_models_pytorch as sm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from torch.autograd import Variable\n",
    "from losses_pytorch.segmentation.twodim.entropy_based_losses import cross_entropy_with_logits_loss\n",
    "\n",
    "from precode.models import UnetSm\n",
    "from precode.scoring import jaccard_score\n",
    "from precode.labels.wheat_segmentation import WHEAT_LABELS\n",
    "from precode.net_utils import init_determenistic, batch_ids_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jupyter-fly_cv/Igor/Plants/'\n",
    "file_path_2 = '/home/jupyter-fly_cv/Igor/Plants_2/Segment/val/for_val_Pl_2'\n",
    "file_path_3 = '/home/jupyter-fly_cv/Igor/Plants/New_json/train'\n",
    "file_path_4 = '/home/jupyter-fly_cv/Igor/Plants/New_json/test'\n",
    "model_checker_path = '/home/jupyter-fly_cv/Igor/Plants/model_segmentation_checker.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "infer_aug = A.Compose([ \n",
    "                        A.Resize ( height=512,\n",
    "                                   width=512,\n",
    "                                   interpolation=1,\n",
    "                                   always_apply=False,\n",
    "                                   p=1. ),\n",
    "                        A.Normalize ( mean=(0.485, 0.456, 0.406),\n",
    "                                      std=(0.229, 0.224, 0.225),\n",
    "                                      max_pixel_value=255.0,\n",
    "                                      always_apply=False,\n",
    "                                      p=1.0 )\n",
    "                      ])\n",
    "\n",
    "\n",
    "class UnetSm(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = sm.Unet(in_channels=in_channels, classes=out_channels, **kwargs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.unet(inputs)\n",
    "\n",
    "def inverse_infer_aug(height, width):\n",
    "    return A.Compose([\n",
    "                       A.Resize ( height=height,\n",
    "                                  width=width,\n",
    "                                  interpolation=cv2.INTER_NEAREST,\n",
    "                                  always_apply=False,\n",
    "                                  p=1. ) \n",
    "                    ])\n",
    "\n",
    "    \n",
    "def create_model(model_file):\n",
    "    model = UnetSm( out_channels=2,\n",
    "                    encoder_name='efficientnet-b0' )\n",
    " \n",
    "    with open(model_file, 'rb') as f:\n",
    "        state = pickle.load(f)\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def torch_float(data, device):\n",
    "    return Variable(torch.FloatTensor(data)).to(device)\n",
    "\n",
    "def augmented_load(img, aug):\n",
    "    auged = aug(image=img)\n",
    "    aug_img = auged['image']\n",
    "\n",
    "    aug_img = aug_img.transpose(2, 0, 1)\n",
    "\n",
    "    return np.array([aug_img])\n",
    "\n",
    "def infer(model, img):\n",
    "    \n",
    "    imgs_batch_ = augmented_load(img, infer_aug)\n",
    "    imgs_batch = torch_float(imgs_batch_, torch.device('cuda'))\n",
    "\n",
    "    logits_batch = model(imgs_batch)\n",
    "\n",
    "    pred_masks_batch = logits_batch.argmax(dim=1)\n",
    "    pred_mask = pred_masks_batch.cpu().data.numpy()#[0]\n",
    "      #  print(pred_masks_batch.cpu().data.numpy().shape)\n",
    "\n",
    "    original_size = img.shape[:2]\n",
    "\n",
    "    original_pred_mask = inverse_infer_aug(*original_size)(image=pred_mask)['image']\n",
    "    original_pred_mask = original_pred_mask.astype('uint8') * 255 \n",
    "\n",
    "    return original_pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(name):\n",
    "    file = open(name,'r')\n",
    "    str_file = file.read()\n",
    "    j = json.loads(str_file)\n",
    "    file.close()\n",
    "    return j\n",
    "\n",
    "def square(poligon):\n",
    "    sq = 0\n",
    "    n = len(poligon)\n",
    "    for i in range(0,n-1):\n",
    "        sq += poligon[i][0]*poligon[i+1][1]\n",
    "    sq +=poligon[n-1][0]*poligon[0][1]\n",
    "    for i in range(0,n-1):\n",
    "        sq -= poligon[i+1][0]*poligon[i][1]\n",
    "    sq -=poligon[0][0]*poligon[n-1][1]\n",
    "    return mth.fabs(sq)/2\n",
    "\n",
    "def all_json_img(imgs_path):\n",
    "    img_names = []\n",
    "\n",
    "    for dirname, _, filenames in os.walk(imgs_path):\n",
    "        for filename in filenames: \n",
    "            name = os.path.join(filename)\n",
    "            if name.split('.')[-1] != 'json':\n",
    "                continue\n",
    "            img_names.append(dirname + '/' + name)\n",
    "            \n",
    "    return img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_jpg_img(imgs_path):\n",
    "    img_names = []\n",
    "\n",
    "    for dirname, _, filenames in os.walk(imgs_path):\n",
    "        for filename in filenames: \n",
    "            name = os.path.join(filename)\n",
    "            if name.split('.')[-1] != 'jpg':\n",
    "                continue\n",
    "            img_names.append(dirname + '/' + name)\n",
    "            \n",
    "    return img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poligons_square(poligons):\n",
    "    sq = 0\n",
    "    for poligon in poligons:\n",
    "        sq += square(poligon['points'])\n",
    "    return sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_checker(img):\n",
    "    img_checker = infer(create_model(model_checker_path),img)\n",
    "    img_checker = cv2.GaussianBlur(img_checker, (21, 21), 0)\n",
    "    img_checker = 1 - np.round(img_checker/255)\n",
    "    return img_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker_mass():\n",
    "    checker = infer(create_model(model_checker_path),img)\n",
    "    checker_count = 0\n",
    "    for i in range(checker.shape[0]):\n",
    "        for j in range(checker.shape[1]):\n",
    "            if checker[i][j] == 0:\n",
    "                checker_count += 1\n",
    "    return checker_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_with_B_mass(b_mass):\n",
    "    df = pd.DataFrame(b_mass,columns = ['Name', 'Bio_Mass'])\n",
    "    df.to_csv('bio_mass_json.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(poligons, height, width):\n",
    "    mask = np.zeros((height,width),dtype=np.uint8)\n",
    "    for poligon in poligons:\n",
    "        cv2.fillPoly(mask,np.array([poligon['points']],dtype = np.int32), 255)\n",
    "    return mask    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_suff_png(name, suff):\n",
    "    names = name.split('/')\n",
    "    png_names = names[-1].split('.')\n",
    "    names[-1] = png_names[0] + suff +'.' + 'png'\n",
    "    new_name = ''\n",
    "    for n in names:\n",
    "        if n != names[-1]:\n",
    "            new_name =new_name + n + '/'\n",
    "        else:\n",
    "            new_name =new_name + n\n",
    "    return new_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_JPG(name):\n",
    "    names = name.split('.')\n",
    "    return names[0] + '.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-fly_cv/Igor/Plants_2/Segment/train/101MEDIA_DJI_0655.JPG'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rename_JPG('/home/jupyter-fly_cv/Igor/Plants_2/Segment/train/101MEDIA_DJI_0655.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = all_json_img(file_path_2)\n",
    "#b_mass = []\n",
    "for name in file_names:\n",
    "    #name = '/home/jupyter-fly_cv/Igor/Plants_2/Segment/train/101MEDIA_DJI_0655.jpg'\n",
    "    #plt.imshow(img)\n",
    "    poligons = read(name) \n",
    "    #b_m = poligons_square(poligons['shapes'])/(poligons['imageHeight']*poligons['imageWidth'])\n",
    "    #b_m = b_m/checker_mass()\n",
    "    #b_mass.append([name.split('/')[-1].split('.')[0],b_m])\n",
    "    mask = create_mask(poligons['shapes'],poligons['imageHeight'],poligons['imageWidth'])\n",
    "    mask_name = filename_suff_png(name, '')\n",
    "    cv2.imwrite(mask_name,mask)\n",
    "    \n",
    "#create_table_with_B_mass(b_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = all_jpg_img(file_path_2)\n",
    "#b_mass = []\n",
    "for name in file_names:\n",
    "    os.rename(name, rename_JPG(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 11 11:54:43 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 27%   40C    P8    25W / 250W |   9391MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:0A:00.0 Off |                  N/A |\r\n",
      "| 27%   36C    P8    21W / 250W |      3MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     18760      C   /opt/tljh/user/bin/python        1207MiB |\r\n",
      "|    0   N/A  N/A     19000      C   /opt/tljh/user/bin/python        8181MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
